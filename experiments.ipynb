{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"common\"))\n",
    "from evaluate import evaluate_predictions\n",
    "from preprocess import getdfs, get_char_columns, one_hot_encode, find_common_characters, remove_common_characters, process_strings\n",
    "from evaluate import get_classification_report, evaluate_predictions\n",
    "from models import predict_logistic_regression\n",
    "from models import predict_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_train_df, emoticon_test_df = getdfs(data='emoticon')\n",
    "text_seq_train_df, text_seq_test_df = getdfs(data='text_seq')\n",
    "feature_train_df, feature_test_df = getdfs(data='feature')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from helper import print_accuracy, remove_common_characters, get_char_columns, find_common_characters, process_strings\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emoticon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('datasets/train/train_emoticon.csv')\n",
    "valid_df = pd.read_csv('datasets/valid/valid_emoticon.csv')\n",
    "test_df = pd.read_csv('datasets/test/test_emoticon.csv')\n",
    "\n",
    "train_df['input_emoticon'] = remove_common_characters(train_df['input_emoticon'])\n",
    "valid_df['input_emoticon'] = remove_common_characters(valid_df['input_emoticon'])\n",
    "test_df['input_emoticon'] = remove_common_characters(test_df['input_emoticon'])\n",
    "\n",
    "train_df = get_char_columns(train_df)\n",
    "valid_df = get_char_columns(valid_df)\n",
    "test_df = get_char_columns(test_df)\n",
    "\n",
    "y_train = train_df['label']\n",
    "y_valid = valid_df['label']\n",
    "\n",
    "train_df = train_df.drop('label', axis=1)\n",
    "valid_df = valid_df.drop('label', axis = 1)\n",
    "\n",
    "oh_encoder = OneHotEncoder(handle_unknown = 'ignore')\n",
    "oh_encoder.fit(train_df)\n",
    "\n",
    "\n",
    "x_train = pd.DataFrame(oh_encoder.transform(train_df).toarray())\n",
    "x_valid = pd.DataFrame(oh_encoder.transform(valid_df).toarray())\n",
    "x_test = pd.DataFrame(oh_encoder.transform(test_df).toarray())\n",
    "\n",
    "params = {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
    "\n",
    "model = LogisticRegression(**params, max_iter= 10000)\n",
    "model.fit(x_train, y_train)\n",
    "y_valid_pred = model.predict(x_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emoticon_train_df['input_emoticon'] = strings_after_removal\n",
    "# emoticon_test_df['input_emoticon'] = remove_common_characters(emoticon_test_df['input_emoticon'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7080, 501) (489, 501)\n"
     ]
    }
   ],
   "source": [
    "# train_df = get_char_columns(emoticon_train_df)\n",
    "# test_df = get_char_columns(emoticon_test_df)\n",
    "# emoti_x_train, emoti_x_valid, emoti_y_train, emoti_y_valid = one_hot_encode(train_df, test_df)\n",
    "# # print(x_train.shape, x_valid.shape, y_train.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
    "\n",
    "model = sklearn.linear_model.LogisticRegression(**params, max_iter= 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, max_iter=10000, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, max_iter=10000, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10, max_iter=10000, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(emoti_x_train, emoti_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoti_train_pred_proba = model.predict_proba(x_train)\n",
    "emoti_test_pred_proba = model.predict_proba(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax probabilities for all samples:\n",
      " [[9.56090405e-04 9.99043910e-01]\n",
      " [2.13558318e-08 9.99999979e-01]\n",
      " [1.00000000e+00 2.04260712e-27]\n",
      " [9.99999997e-01 2.90756128e-09]\n",
      " [4.55286105e-06 9.99995447e-01]\n",
      " [2.53751464e-10 1.00000000e+00]\n",
      " [1.01035301e-08 9.99999990e-01]\n",
      " [9.99999999e-01 1.13935484e-09]\n",
      " [9.99999997e-01 2.75185118e-09]\n",
      " [6.54488819e-09 9.99999993e-01]\n",
      " [1.00000000e+00 3.43064038e-17]\n",
      " [1.15298500e-06 9.99998847e-01]\n",
      " [9.82407809e-01 1.75921908e-02]\n",
      " [1.30887186e-07 9.99999869e-01]\n",
      " [2.07771105e-01 7.92228895e-01]\n",
      " [1.00000000e+00 1.88464854e-17]\n",
      " [2.44340861e-06 9.99997557e-01]\n",
      " [3.30598429e-08 9.99999967e-01]\n",
      " [6.53761090e-09 9.99999993e-01]\n",
      " [1.00000000e+00 4.77980850e-22]\n",
      " [9.99999996e-01 3.95652556e-09]\n",
      " [3.52970075e-09 9.99999996e-01]\n",
      " [1.00000000e+00 2.32213370e-19]\n",
      " [1.00000000e+00 4.02264460e-34]\n",
      " [9.88309467e-01 1.16905334e-02]\n",
      " [1.00000000e+00 1.24799399e-19]\n",
      " [1.54078185e-03 9.98459218e-01]\n",
      " [2.06117807e-06 9.99997939e-01]\n",
      " [9.99999911e-01 8.91409257e-08]\n",
      " [2.45359288e-13 1.00000000e+00]\n",
      " [1.00000000e+00 7.48280124e-21]\n",
      " [1.40019092e-08 9.99999986e-01]\n",
      " [9.99999948e-01 5.23521031e-08]\n",
      " [1.00000000e+00 1.86837804e-34]\n",
      " [1.00000000e+00 5.52321071e-28]\n",
      " [2.19106989e-07 9.99999781e-01]\n",
      " [1.00000000e+00 5.84483510e-14]\n",
      " [6.76547396e-09 9.99999993e-01]\n",
      " [1.34012796e-08 9.99999987e-01]\n",
      " [2.14289231e-09 9.99999998e-01]\n",
      " [9.99999994e-01 6.34765708e-09]\n",
      " [5.51114709e-13 1.00000000e+00]\n",
      " [9.70584594e-01 2.94154056e-02]\n",
      " [1.87350994e-08 9.99999981e-01]\n",
      " [2.82634712e-06 9.99997174e-01]\n",
      " [1.15321619e-09 9.99999999e-01]\n",
      " [1.00000000e+00 2.63338556e-20]\n",
      " [1.97775130e-12 1.00000000e+00]\n",
      " [1.50429125e-08 9.99999985e-01]\n",
      " [3.40092390e-07 9.99999660e-01]\n",
      " [1.00000000e+00 1.13103846e-29]\n",
      " [2.08904183e-08 9.99999979e-01]\n",
      " [9.65468828e-01 3.45311724e-02]\n",
      " [3.86866669e-08 9.99999961e-01]\n",
      " [1.16943612e-04 9.99883056e-01]\n",
      " [1.00000000e+00 2.07708919e-13]\n",
      " [1.00000000e+00 1.99955561e-25]\n",
      " [1.00000000e+00 2.47275692e-14]\n",
      " [1.49696796e-01 8.50303204e-01]\n",
      " [4.85862993e-07 9.99999514e-01]\n",
      " [2.92301738e-11 1.00000000e+00]\n",
      " [1.00000000e+00 5.56533570e-20]\n",
      " [2.15076623e-10 1.00000000e+00]\n",
      " [1.00000000e+00 9.12398026e-27]\n",
      " [1.00000000e+00 2.14654380e-12]\n",
      " [9.99999755e-01 2.44858798e-07]\n",
      " [1.00000000e+00 2.19720940e-12]\n",
      " [6.99839697e-08 9.99999930e-01]\n",
      " [8.18678458e-13 1.00000000e+00]\n",
      " [3.74178466e-11 1.00000000e+00]\n",
      " [1.00000000e+00 3.35263594e-15]\n",
      " [9.97931582e-01 2.06841762e-03]\n",
      " [5.09030357e-08 9.99999949e-01]\n",
      " [5.35329558e-11 1.00000000e+00]\n",
      " [6.66334448e-07 9.99999334e-01]\n",
      " [1.00000000e+00 4.38391908e-23]\n",
      " [9.99997487e-01 2.51279721e-06]\n",
      " [1.00000000e+00 3.55621646e-10]\n",
      " [1.00000000e+00 8.12645300e-20]\n",
      " [1.17175405e-06 9.99998828e-01]\n",
      " [7.76808756e-05 9.99922319e-01]\n",
      " [2.78932433e-10 1.00000000e+00]\n",
      " [1.00000000e+00 1.08189930e-33]\n",
      " [6.82352102e-01 3.17647898e-01]\n",
      " [1.00000000e+00 2.58739651e-16]\n",
      " [2.95721225e-11 1.00000000e+00]\n",
      " [4.04010706e-08 9.99999960e-01]\n",
      " [9.66252378e-09 9.99999990e-01]\n",
      " [4.20504409e-06 9.99995795e-01]\n",
      " [1.00000000e+00 1.10519376e-19]\n",
      " [1.00000000e+00 1.96399144e-14]\n",
      " [9.97518136e-01 2.48186428e-03]\n",
      " [1.00000000e+00 4.24022969e-33]\n",
      " [5.11368028e-08 9.99999949e-01]\n",
      " [7.05975278e-11 1.00000000e+00]\n",
      " [2.90714119e-10 1.00000000e+00]\n",
      " [1.01983422e-05 9.99989802e-01]\n",
      " [2.41382171e-04 9.99758618e-01]\n",
      " [3.67648578e-01 6.32351422e-01]\n",
      " [1.00000000e+00 3.24219908e-18]\n",
      " [5.85986948e-09 9.99999994e-01]\n",
      " [1.00000000e+00 8.29363194e-33]\n",
      " [1.00000000e+00 7.11715813e-26]\n",
      " [9.99972464e-01 2.75363713e-05]\n",
      " [3.80766294e-07 9.99999619e-01]\n",
      " [1.00000000e+00 1.11507736e-15]\n",
      " [9.56578516e-09 9.99999990e-01]\n",
      " [3.20419973e-05 9.99967958e-01]\n",
      " [3.88770640e-08 9.99999961e-01]\n",
      " [1.36668454e-12 1.00000000e+00]\n",
      " [4.99070262e-07 9.99999501e-01]\n",
      " [3.71842623e-09 9.99999996e-01]\n",
      " [4.16490242e-09 9.99999996e-01]\n",
      " [2.04944314e-02 9.79505569e-01]\n",
      " [4.06975453e-09 9.99999996e-01]\n",
      " [1.41678891e-09 9.99999999e-01]\n",
      " [9.99669977e-01 3.30023324e-04]\n",
      " [1.00000000e+00 8.42360960e-12]\n",
      " [1.76768689e-09 9.99999998e-01]\n",
      " [1.00000000e+00 1.96776688e-16]\n",
      " [7.89027283e-05 9.99921097e-01]\n",
      " [2.87120994e-10 1.00000000e+00]\n",
      " [1.00000000e+00 1.37230670e-22]\n",
      " [6.41564362e-04 9.99358436e-01]\n",
      " [1.00000000e+00 2.47813196e-28]\n",
      " [1.00000000e+00 6.14549644e-29]\n",
      " [9.99538155e-01 4.61844540e-04]\n",
      " [9.99999999e-01 6.93712885e-10]\n",
      " [1.00000000e+00 3.69207839e-10]\n",
      " [1.00000000e+00 2.27459404e-20]\n",
      " [1.00000000e+00 3.58039596e-22]\n",
      " [1.00000000e+00 1.55130643e-24]\n",
      " [9.99999867e-01 1.33405316e-07]\n",
      " [2.83638896e-08 9.99999972e-01]\n",
      " [1.00000000e+00 2.39904201e-42]\n",
      " [6.47771245e-01 3.52228755e-01]\n",
      " [1.00000000e+00 3.29780388e-23]\n",
      " [1.00000000e+00 5.49124350e-28]\n",
      " [1.00000000e+00 7.85259223e-23]\n",
      " [1.48272800e-07 9.99999852e-01]\n",
      " [8.34971487e-06 9.99991650e-01]\n",
      " [6.94484470e-11 1.00000000e+00]\n",
      " [9.98941670e-01 1.05833012e-03]\n",
      " [9.26868193e-09 9.99999991e-01]\n",
      " [1.20771196e-08 9.99999988e-01]\n",
      " [1.83181929e-02 9.81681807e-01]\n",
      " [1.00000000e+00 2.53310907e-13]\n",
      " [1.00000000e+00 9.89025336e-18]\n",
      " [9.99999999e-01 1.06924315e-09]\n",
      " [1.08352053e-03 9.98916479e-01]\n",
      " [1.08456078e-03 9.98915439e-01]\n",
      " [2.67275091e-12 1.00000000e+00]\n",
      " [1.00000000e+00 1.29079510e-38]\n",
      " [2.90800396e-06 9.99997092e-01]\n",
      " [7.67314627e-01 2.32685373e-01]\n",
      " [6.14151670e-07 9.99999386e-01]\n",
      " [1.00000000e+00 2.86820080e-35]\n",
      " [1.62241627e-07 9.99999838e-01]\n",
      " [1.00000000e+00 1.06708239e-32]\n",
      " [1.04805054e-13 1.00000000e+00]\n",
      " [1.88737914e-14 1.00000000e+00]\n",
      " [5.47752954e-11 1.00000000e+00]\n",
      " [9.99999992e-01 7.63342170e-09]\n",
      " [3.79896115e-12 1.00000000e+00]\n",
      " [2.23525289e-07 9.99999776e-01]\n",
      " [1.77072615e-03 9.98229274e-01]\n",
      " [1.00000000e+00 1.59255588e-44]\n",
      " [4.00990352e-11 1.00000000e+00]\n",
      " [1.66938298e-07 9.99999833e-01]\n",
      " [9.99999997e-01 2.80226698e-09]\n",
      " [2.18134404e-07 9.99999782e-01]\n",
      " [1.00000000e+00 4.98850688e-21]\n",
      " [9.99941399e-01 5.86006585e-05]\n",
      " [1.00000000e+00 1.46046363e-36]\n",
      " [1.30736852e-08 9.99999987e-01]\n",
      " [8.37747126e-01 1.62252874e-01]\n",
      " [4.63553451e-05 9.99953645e-01]\n",
      " [1.00000000e+00 3.22733842e-25]\n",
      " [2.12759822e-07 9.99999787e-01]\n",
      " [7.30526750e-14 1.00000000e+00]\n",
      " [1.84623672e-09 9.99999998e-01]\n",
      " [4.97474373e-04 9.99502526e-01]\n",
      " [4.87196369e-07 9.99999513e-01]\n",
      " [9.99999671e-01 3.29284131e-07]\n",
      " [1.00000000e+00 3.93710253e-22]\n",
      " [1.00000000e+00 4.50873677e-15]\n",
      " [1.90811256e-09 9.99999998e-01]\n",
      " [1.00000000e+00 5.49787566e-17]\n",
      " [5.72456960e-07 9.99999428e-01]\n",
      " [1.00000000e+00 4.97455105e-26]\n",
      " [1.43115241e-04 9.99856885e-01]\n",
      " [3.50194062e-01 6.49805938e-01]\n",
      " [9.45322055e-06 9.99990547e-01]\n",
      " [6.35670903e-08 9.99999936e-01]\n",
      " [3.01563018e-07 9.99999698e-01]\n",
      " [9.65106189e-01 3.48938105e-02]\n",
      " [1.00000000e+00 7.56156945e-24]\n",
      " [7.49065687e-02 9.25093431e-01]\n",
      " [1.77541814e-01 8.22458186e-01]\n",
      " [1.00000000e+00 1.52205974e-27]\n",
      " [4.79477216e-07 9.99999521e-01]\n",
      " [2.96005150e-05 9.99970399e-01]\n",
      " [1.00000000e+00 8.23856951e-29]\n",
      " [9.99999980e-01 1.99241848e-08]\n",
      " [8.01790812e-06 9.99991982e-01]\n",
      " [5.51494325e-07 9.99999449e-01]\n",
      " [1.82154370e-05 9.99981785e-01]\n",
      " [1.00000000e+00 2.51231533e-33]\n",
      " [1.00000000e+00 1.40714437e-12]\n",
      " [2.93991498e-11 1.00000000e+00]\n",
      " [1.00000000e+00 8.11600162e-13]\n",
      " [1.00000000e+00 2.02689159e-24]\n",
      " [1.95148342e-11 1.00000000e+00]\n",
      " [5.72434939e-02 9.42756506e-01]\n",
      " [1.73678577e-07 9.99999826e-01]\n",
      " [1.34485894e-08 9.99999987e-01]\n",
      " [1.00000000e+00 9.67356730e-26]\n",
      " [1.00000000e+00 1.01905593e-11]\n",
      " [2.60390329e-05 9.99973961e-01]\n",
      " [1.00000000e+00 1.63694346e-30]\n",
      " [1.45757555e-07 9.99999854e-01]\n",
      " [1.00000000e+00 2.06518488e-16]\n",
      " [1.00000000e+00 3.08124462e-15]\n",
      " [9.04747135e-07 9.99999095e-01]\n",
      " [8.72438258e-05 9.99912756e-01]\n",
      " [4.66135236e-07 9.99999534e-01]\n",
      " [1.01168629e-10 1.00000000e+00]\n",
      " [4.03194811e-10 1.00000000e+00]\n",
      " [1.00000000e+00 8.60485350e-18]\n",
      " [2.73618905e-11 1.00000000e+00]\n",
      " [1.00000000e+00 7.57753168e-14]\n",
      " [8.34887715e-13 1.00000000e+00]\n",
      " [9.99954690e-01 4.53098802e-05]\n",
      " [9.99999999e-01 5.09354735e-10]\n",
      " [3.14672288e-10 1.00000000e+00]\n",
      " [1.00000000e+00 2.12857293e-40]\n",
      " [1.00000000e+00 3.28433269e-24]\n",
      " [1.00000000e+00 2.12435651e-25]\n",
      " [1.96256420e-05 9.99980374e-01]\n",
      " [1.00000000e+00 2.00353543e-10]\n",
      " [1.00000000e+00 1.33030468e-15]\n",
      " [1.03080464e-07 9.99999897e-01]\n",
      " [1.00000000e+00 4.16015102e-36]\n",
      " [6.12235329e-09 9.99999994e-01]\n",
      " [1.00000000e+00 3.73483956e-22]\n",
      " [2.90411672e-09 9.99999997e-01]\n",
      " [9.99999470e-01 5.30409130e-07]\n",
      " [1.00000000e+00 1.31886672e-27]\n",
      " [1.00000000e+00 3.35988033e-21]\n",
      " [2.65032440e-12 1.00000000e+00]\n",
      " [1.00000000e+00 8.81398165e-12]\n",
      " [9.95154439e-01 4.84556144e-03]\n",
      " [5.26965761e-07 9.99999473e-01]\n",
      " [9.99998669e-01 1.33114203e-06]\n",
      " [1.00000000e+00 1.12643219e-13]\n",
      " [1.00000000e+00 1.66461514e-18]\n",
      " [7.07559714e-08 9.99999929e-01]\n",
      " [3.84822699e-06 9.99996152e-01]\n",
      " [1.00000000e+00 7.49548433e-51]\n",
      " [1.00000000e+00 7.45706800e-30]\n",
      " [9.99999994e-01 5.98732132e-09]\n",
      " [3.65090225e-09 9.99999996e-01]\n",
      " [1.00000000e+00 2.06827012e-13]\n",
      " [1.00000000e+00 4.69466914e-21]\n",
      " [1.99426387e-09 9.99999998e-01]\n",
      " [1.00000000e+00 2.62379021e-23]\n",
      " [2.79056334e-10 1.00000000e+00]\n",
      " [3.73380149e-09 9.99999996e-01]\n",
      " [4.83628248e-01 5.16371752e-01]\n",
      " [2.40417868e-03 9.97595821e-01]\n",
      " [1.00000000e+00 2.47158865e-18]\n",
      " [1.00000000e+00 1.25457055e-23]\n",
      " [1.00000000e+00 2.15299955e-11]\n",
      " [9.99999889e-01 1.10974177e-07]\n",
      " [1.00000000e+00 1.87891976e-15]\n",
      " [1.00000000e+00 3.46919617e-32]\n",
      " [1.93496374e-09 9.99999998e-01]\n",
      " [9.65967227e-01 3.40327731e-02]\n",
      " [8.68035822e-03 9.91319642e-01]\n",
      " [1.00000000e+00 2.24386729e-14]\n",
      " [1.00000000e+00 2.38860952e-10]\n",
      " [2.11129558e-10 1.00000000e+00]\n",
      " [1.00000000e+00 6.62041646e-26]\n",
      " [1.00000000e+00 1.93555891e-18]\n",
      " [9.99998567e-01 1.43305219e-06]\n",
      " [1.00000000e+00 6.78313449e-21]\n",
      " [1.00000000e+00 2.88762278e-13]\n",
      " [1.00000000e+00 6.24912724e-22]\n",
      " [1.70204528e-06 9.99998298e-01]\n",
      " [9.99995453e-01 4.54657084e-06]\n",
      " [1.00000000e+00 5.66909770e-30]\n",
      " [1.00000000e+00 8.69704940e-21]\n",
      " [9.93875104e-01 6.12489619e-03]\n",
      " [1.00000000e+00 7.93429616e-24]\n",
      " [5.88418203e-14 1.00000000e+00]\n",
      " [2.55728201e-08 9.99999974e-01]\n",
      " [4.29797884e-06 9.99995702e-01]\n",
      " [1.00000000e+00 3.20896925e-10]\n",
      " [1.93878047e-09 9.99999998e-01]\n",
      " [1.00000000e+00 2.84092632e-27]\n",
      " [1.00000000e+00 4.22190530e-32]\n",
      " [1.00000000e+00 1.51187506e-10]\n",
      " [3.85568293e-01 6.14431707e-01]\n",
      " [2.28776772e-03 9.97712232e-01]\n",
      " [1.48613274e-02 9.85138673e-01]\n",
      " [1.00000000e+00 1.84203981e-17]\n",
      " [1.00000000e+00 2.54400133e-11]\n",
      " [1.00000000e+00 7.99551879e-18]\n",
      " [1.00000000e+00 3.70956045e-35]\n",
      " [9.80529341e-01 1.94706593e-02]\n",
      " [8.59329740e-01 1.40670260e-01]\n",
      " [1.85200411e-09 9.99999998e-01]\n",
      " [9.93209937e-01 6.79006325e-03]\n",
      " [1.00000000e+00 2.06086181e-18]\n",
      " [1.00000000e+00 8.06204847e-19]\n",
      " [1.00000000e+00 3.87571405e-20]\n",
      " [1.00000000e+00 6.50502310e-16]\n",
      " [6.17722464e-08 9.99999938e-01]\n",
      " [1.00000000e+00 1.23501032e-14]\n",
      " [2.31009927e-04 9.99768990e-01]\n",
      " [1.00000000e+00 3.67877465e-28]\n",
      " [1.00000000e+00 9.57038808e-22]\n",
      " [1.00000000e+00 2.74034483e-20]\n",
      " [1.00000000e+00 7.64240061e-28]\n",
      " [9.60315986e-04 9.99039684e-01]\n",
      " [9.99987938e-01 1.20616768e-05]\n",
      " [1.66665247e-04 9.99833335e-01]\n",
      " [9.99960045e-01 3.99546904e-05]\n",
      " [9.99999999e-01 6.46919881e-10]\n",
      " [1.06581410e-14 1.00000000e+00]\n",
      " [1.64732672e-11 1.00000000e+00]\n",
      " [4.27924007e-09 9.99999996e-01]\n",
      " [1.00000000e+00 5.96373250e-26]\n",
      " [1.00000000e+00 1.72417045e-16]\n",
      " [6.45048518e-02 9.35495148e-01]\n",
      " [1.00000000e+00 3.15964757e-31]\n",
      " [1.00000000e+00 3.33177608e-12]\n",
      " [1.00000000e+00 1.30690337e-25]\n",
      " [1.00000000e+00 4.48673076e-10]\n",
      " [1.00000000e+00 7.35050188e-16]\n",
      " [2.47653992e-01 7.52346008e-01]\n",
      " [1.00000000e+00 2.28811737e-14]\n",
      " [1.52690054e-06 9.99998473e-01]\n",
      " [6.69616862e-07 9.99999330e-01]\n",
      " [6.44437475e-07 9.99999356e-01]\n",
      " [9.99999791e-01 2.08509586e-07]\n",
      " [5.95479221e-11 1.00000000e+00]\n",
      " [9.99975250e-01 2.47499832e-05]\n",
      " [8.90835419e-01 1.09164581e-01]\n",
      " [9.94819394e-01 5.18060583e-03]\n",
      " [4.45752657e-09 9.99999996e-01]\n",
      " [5.32655950e-02 9.46734405e-01]\n",
      " [1.00000000e+00 9.31041804e-27]\n",
      " [9.99999972e-01 2.75682442e-08]\n",
      " [9.99188677e-01 8.11323112e-04]\n",
      " [1.90306437e-10 1.00000000e+00]\n",
      " [1.98906725e-07 9.99999801e-01]\n",
      " [1.00000000e+00 9.43957628e-13]\n",
      " [4.90881682e-05 9.99950912e-01]\n",
      " [1.00000000e+00 1.33881298e-28]\n",
      " [1.00000000e+00 3.99608505e-32]\n",
      " [1.38011733e-06 9.99998620e-01]\n",
      " [1.00000000e+00 1.20346991e-15]\n",
      " [3.37819046e-08 9.99999966e-01]\n",
      " [3.77420922e-08 9.99999962e-01]\n",
      " [9.99997495e-01 2.50533309e-06]\n",
      " [1.60859996e-01 8.39140004e-01]\n",
      " [1.67154686e-02 9.83284531e-01]\n",
      " [1.34021507e-08 9.99999987e-01]\n",
      " [7.17084481e-01 2.82915519e-01]\n",
      " [9.99999967e-01 3.32308688e-08]\n",
      " [6.27782949e-01 3.72217051e-01]\n",
      " [9.99999999e-01 7.71426422e-10]\n",
      " [1.67855364e-07 9.99999832e-01]\n",
      " [1.16266996e-11 1.00000000e+00]\n",
      " [1.00000000e+00 5.35094198e-31]\n",
      " [7.80486786e-13 1.00000000e+00]\n",
      " [1.66338739e-07 9.99999834e-01]\n",
      " [9.99999997e-01 2.60186591e-09]\n",
      " [9.99658815e-01 3.41185009e-04]\n",
      " [1.00000000e+00 4.15090039e-21]\n",
      " [4.64909144e-05 9.99953509e-01]\n",
      " [4.17432707e-06 9.99995826e-01]\n",
      " [1.00103872e-06 9.99998999e-01]\n",
      " [1.00000000e+00 2.56793686e-27]\n",
      " [9.97984048e-01 2.01595164e-03]\n",
      " [5.90820325e-08 9.99999941e-01]\n",
      " [5.53656410e-09 9.99999994e-01]\n",
      " [1.00000000e+00 3.37615366e-14]\n",
      " [1.91812122e-10 1.00000000e+00]\n",
      " [2.91597420e-08 9.99999971e-01]\n",
      " [1.00000000e+00 5.19591393e-19]\n",
      " [1.00000000e+00 1.79281113e-14]\n",
      " [5.70536910e-03 9.94294631e-01]\n",
      " [1.00000000e+00 1.81603870e-10]\n",
      " [3.31385598e-07 9.99999669e-01]\n",
      " [1.00000000e+00 3.23967355e-34]\n",
      " [1.00000000e+00 1.71699748e-24]\n",
      " [1.98120409e-10 1.00000000e+00]\n",
      " [9.99424074e-01 5.75926243e-04]\n",
      " [1.19881882e-12 1.00000000e+00]\n",
      " [9.99999994e-01 5.56939435e-09]\n",
      " [1.00000000e+00 4.82031067e-22]\n",
      " [7.86303151e-03 9.92136968e-01]\n",
      " [3.45046292e-06 9.99996550e-01]\n",
      " [9.99999939e-01 6.11745444e-08]\n",
      " [5.11132520e-04 9.99488867e-01]\n",
      " [1.00000000e+00 3.67243182e-23]\n",
      " [1.05648823e-11 1.00000000e+00]\n",
      " [1.80652425e-07 9.99999819e-01]\n",
      " [7.16216539e-07 9.99999284e-01]\n",
      " [3.02380099e-08 9.99999970e-01]\n",
      " [1.46102686e-10 1.00000000e+00]\n",
      " [9.70666700e-01 2.93332997e-02]\n",
      " [7.92049890e-01 2.07950110e-01]\n",
      " [1.00000000e+00 5.95128544e-26]\n",
      " [9.99999747e-01 2.52658430e-07]\n",
      " [1.00000000e+00 4.48257599e-12]\n",
      " [9.83952220e-09 9.99999990e-01]\n",
      " [3.59035268e-07 9.99999641e-01]\n",
      " [1.00000000e+00 2.88366857e-35]\n",
      " [1.00000000e+00 7.55234631e-15]\n",
      " [9.97569622e-01 2.43037837e-03]\n",
      " [9.99999895e-01 1.04824410e-07]\n",
      " [6.74463180e-06 9.99993255e-01]\n",
      " [1.00000000e+00 3.30096912e-12]\n",
      " [1.00000000e+00 3.59532984e-32]\n",
      " [2.44249065e-15 1.00000000e+00]\n",
      " [1.51555949e-07 9.99999848e-01]\n",
      " [1.27229451e-03 9.98727705e-01]\n",
      " [1.00000000e+00 1.31732141e-24]\n",
      " [1.00000000e+00 5.38178485e-18]\n",
      " [6.69980760e-09 9.99999993e-01]\n",
      " [1.72483139e-10 1.00000000e+00]\n",
      " [9.99502645e-01 4.97354817e-04]\n",
      " [5.16797696e-01 4.83202304e-01]\n",
      " [9.99878741e-01 1.21258681e-04]\n",
      " [4.44681816e-08 9.99999956e-01]\n",
      " [9.99997729e-01 2.27066747e-06]\n",
      " [1.00000000e+00 2.70709300e-17]\n",
      " [9.99940273e-01 5.97268338e-05]\n",
      " [3.22710695e-05 9.99967729e-01]\n",
      " [2.44145815e-10 1.00000000e+00]\n",
      " [4.38197778e-03 9.95618022e-01]\n",
      " [2.22635244e-11 1.00000000e+00]\n",
      " [5.66687713e-06 9.99994333e-01]\n",
      " [1.00000000e+00 1.33900929e-15]\n",
      " [3.18964655e-09 9.99999997e-01]\n",
      " [9.99996288e-01 3.71242286e-06]\n",
      " [1.00000000e+00 2.29995858e-26]\n",
      " [1.35195935e-07 9.99999865e-01]\n",
      " [1.75032267e-06 9.99998250e-01]\n",
      " [1.00000000e+00 1.15001810e-18]\n",
      " [2.93098879e-14 1.00000000e+00]\n",
      " [8.94460882e-02 9.10553912e-01]\n",
      " [1.07155528e-08 9.99999989e-01]\n",
      " [9.99993068e-01 6.93205355e-06]\n",
      " [1.00000000e+00 4.30544776e-31]\n",
      " [1.00000000e+00 1.00270517e-16]\n",
      " [9.99998853e-01 1.14745416e-06]\n",
      " [1.22993470e-07 9.99999877e-01]\n",
      " [1.80681629e-08 9.99999982e-01]\n",
      " [9.32587341e-15 1.00000000e+00]\n",
      " [1.00000000e+00 6.89860509e-30]\n",
      " [1.80395698e-11 1.00000000e+00]\n",
      " [1.00000000e+00 1.95789673e-24]\n",
      " [1.00000000e+00 3.74203691e-10]\n",
      " [6.12522734e-07 9.99999387e-01]\n",
      " [5.07523656e-07 9.99999492e-01]\n",
      " [8.50395310e-11 1.00000000e+00]\n",
      " [1.74801729e-10 1.00000000e+00]\n",
      " [9.99999928e-01 7.15047729e-08]\n",
      " [5.73358694e-01 4.26641306e-01]\n",
      " [1.05870075e-01 8.94129925e-01]\n",
      " [1.00000000e+00 1.07748215e-15]\n",
      " [8.43243182e-08 9.99999916e-01]\n",
      " [1.00000000e+00 1.04682737e-20]\n",
      " [1.19371868e-07 9.99999881e-01]\n",
      " [9.78830832e-08 9.99999902e-01]\n",
      " [1.97044013e-07 9.99999803e-01]\n",
      " [1.89349999e-07 9.99999811e-01]\n",
      " [5.66213743e-14 1.00000000e+00]\n",
      " [1.79486113e-06 9.99998205e-01]\n",
      " [3.92796906e-13 1.00000000e+00]\n",
      " [4.79707385e-11 1.00000000e+00]\n",
      " [1.00000000e+00 8.52803292e-26]\n",
      " [9.99999997e-01 2.74815628e-09]\n",
      " [9.99999993e-01 7.36391751e-09]\n",
      " [1.00000000e+00 2.06112004e-15]]\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # Train the MLP model (assuming you have already trained it)\n",
    "# mlp_model = MLPClassifier(hidden_layer_sizes=(16,), max_iter=1000)\n",
    "# mlp_model.fit(x_train, y_train)\n",
    "\n",
    "# # Predict probabilities for each class (softmax output for all samples)\n",
    "# y_proba_mlp = mlp_model.predict_proba(x_valid)\n",
    "\n",
    "# # Display softmax probabilities for all samples\n",
    "# print(\"Softmax probabilities for all samples:\\n\", y_proba_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = np.load('datasets/train/train_feature.npz', allow_pickle=True)\n",
    "valid_df = np.load('datasets/valid/valid_feature.npz', allow_pickle=True)\n",
    "test_df = np.load('datasets/test/test_feature.npz', allow_pickle=True)\n",
    "\n",
    "x_train = train_df['features']\n",
    "y_train = train_df['label']\n",
    "x_valid = valid_df['features']\n",
    "y_valid = valid_df['label']\n",
    "x_test = test_df['features']\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], -1)\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "params = {'C': 10.0, 'fit_intercept': True, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
    "model = LogisticRegression(**params, max_iter= 1000)\n",
    "model.fit(x_train, y_train)\n",
    "y_valid_pred = model.predict(x_valid)\n",
    "\n",
    "# print_accuracy(y_valid, y_valid_pred)\n",
    "\n",
    "# generate_submission_txt(model, x_test, file_name='pred_deepfeat.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "\n",
    "\n",
    "model = sklearn.linear_model.LogisticRegression(max_iter=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=10000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=10000, random_state=42)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train_pred_proba = model.predict_proba(x_train)\n",
    "feature_test_pred_proba = model.predict_proba(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_y_pred = predict_proba_logistic_regression(train_X, train_Y, valid_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import typing\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../common\"))  # add path to common functions\n",
    "from evaluate import evaluate_predictions\n",
    "from preprocess import getdfs, get_char_columns\n",
    "from preprocess import one_hot_encode\n",
    "from models import predict_logistic_regression\n",
    "from models import predict_xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "repeat_emos = ['🙼', '🛐', '🙯', '😛', '😣', '😑', '🚼']\n",
    "\n",
    "repeat_emo_code = {\n",
    "     '🙼' : '284',\n",
    "     '🛐' : '464', \n",
    "     '🙯' : '262',\n",
    "     '😛' : '15436', \n",
    "     '😣' : '614',\n",
    "     '😑' : '1596', \n",
    "     '🚼' : '422'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "emo_train_df = pd.read_csv('datasets/train/train_emoticon.csv')\n",
    "repeat_emos = find_common_characters(emo_train_df['input_emoticon'])\n",
    "\n",
    "train_df = pd.read_csv('datasets/train/train_text_seq.csv')\n",
    "valid_df = pd.read_csv('datasets/valid/valid_text_seq.csv')\n",
    "test_df = pd.read_csv('datasets/test/test_text_seq.csv')\n",
    "\n",
    "train_df[\"input_str\"] = process_strings(train_df[\"input_str\"])\n",
    "valid_df[\"input_str\"] = process_strings(valid_df[\"input_str\"])\n",
    "test_df[\"input_str\"] = process_strings(test_df[\"input_str\"])\n",
    "\n",
    "y_train = train_df['label'].values\n",
    "y_valid = valid_df['label'].values\n",
    "\n",
    "_x_train = train_df['input_str'].values\n",
    "_x_valid = valid_df['input_str'].values\n",
    "_x_test = test_df['input_str'].values\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(3, 5), analyzer='char')  # Extract n-grams\n",
    "\n",
    "x_train = vectorizer.fit_transform(_x_train)\n",
    "x_valid = vectorizer.transform(_x_valid)\n",
    "x_test = vectorizer.transform(_x_test)\n",
    "\n",
    "params  = {'colsample_bytree': 1.0, 'eval_metric': 'logloss', 'gamma': 0.2, 'learning_rate': 0.1, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 500, 'subsample': 1.0}\n",
    "model = XGBClassifier(**params)\n",
    "model.fit(x_train, y_train)\n",
    "y_valid_pred = model.predict(x_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_seq_train_df['input_str'] = process_strings(text_seq_train_df['input_str'])\n",
    "text_seq_test_df['input_str'] = process_strings(text_seq_test_df['input_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feat = 15\n",
    "\n",
    "def get_columns (df) :\n",
    "    for i in range(num_feat):\n",
    "        df[f'c_{i}'] = df['input_str'].apply(lambda x : x[i])\n",
    "    return df.drop(columns = ['input_str'])\n",
    "\n",
    "text_seq_train_df = get_columns(text_seq_train_df)\n",
    "text_seq_test_df = get_columns(text_seq_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>c_0</th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>c_6</th>\n",
       "      <th>c_7</th>\n",
       "      <th>c_8</th>\n",
       "      <th>c_9</th>\n",
       "      <th>c_10</th>\n",
       "      <th>c_11</th>\n",
       "      <th>c_12</th>\n",
       "      <th>c_13</th>\n",
       "      <th>c_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label c_0 c_1 c_2 c_3 c_4 c_5 c_6 c_7 c_8 c_9 c_10 c_11 c_12 c_13 c_14\n",
       "0      1   3   3   4   1   4   1   3   9   0   1    0    0    0    0    0\n",
       "1      1   1   2   5   0   6   2   3   2   7   3    1    0    4    0    0\n",
       "2      0   4   5   4   3   6   3   3   6   5   2    7    1    3    0    0\n",
       "3      0   1   1   2   0   4   3   7   1   3   1    3    2    0    0    0\n",
       "4      1   3   3   2   4   2   3   6   8   4   5    7    0    5    0    0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_seq_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7080, 142) (489, 142)\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering (example: one-hot encoding)\n",
    "\n",
    "train_df, valid_df, y_train, y_valid = one_hot_encode(text_seq_train_df, text_seq_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.values\n",
    "x_valid = valid_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_seq_train_pred_proba = model.predict_proba(x_train)\n",
    "text_seq_test_pred_proba = model.predict_proba(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.98      0.99      0.98       250\n",
      "     Class 1       0.99      0.98      0.98       239\n",
      "\n",
      "    accuracy                           0.98       489\n",
      "   macro avg       0.98      0.98      0.98       489\n",
      "weighted avg       0.98      0.98      0.98       489\n",
      "\n",
      "0.983640081799591\n"
     ]
    }
   ],
   "source": [
    "hard_pred = np.array((np.argmax(emoti_test_pred_proba, axis = 1) + np.argmax(feature_test_pred_proba, axis = 1) + np.argmax(text_seq_test_pred_proba, axis = 1)) >= 2, dtype = np.float64)\n",
    "rep = get_classification_report(hard_pred, y_valid)\n",
    "print(rep)\n",
    "print(sklearn.metrics.accuracy_score(hard_pred, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.98      0.98      0.98       250\n",
      "     Class 1       0.98      0.97      0.98       239\n",
      "\n",
      "    accuracy                           0.98       489\n",
      "   macro avg       0.98      0.98      0.98       489\n",
      "weighted avg       0.98      0.98      0.98       489\n",
      "\n",
      "0.9795501022494888\n"
     ]
    }
   ],
   "source": [
    "soft_pred = np.argmax(emoti_test_pred_proba + feature_test_pred_proba + text_seq_test_pred_proba, axis = 1)\n",
    "rep = get_classification_report(soft_pred, y_valid)\n",
    "print(rep)\n",
    "print(sklearn.metrics.accuracy_score(soft_pred, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "train_inputs = torch.tensor(np.hstack([emoti_train_pred_proba[:, 1].reshape(-1, 1), feature_train_pred_proba[:, 1].reshape(-1, 1), text_seq_train_pred_proba[:, 1].reshape(-1,1)]), dtype = torch.float32)\n",
    "train_targets = torch.tensor(y_train.values.reshape(-1, 1), dtype = torch.float32)\n",
    "test_inputs = torch.tensor(np.hstack([emoti_test_pred_proba[:, 1].reshape(-1, 1), feature_test_pred_proba[:, 1].reshape(-1, 1), text_seq_test_pred_proba[:, 1].reshape(-1,1)]), dtype = torch.float32)\n",
    "test_targets = torch.tensor(y_valid.values.reshape(-1, 1), dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple neural network with a single linear layer\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.linear = nn.Linear(3, 1)  # 3 inputs, 1 output\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))  # Apply sigmoid for binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy=1.0000, test_accuracy=0.9673\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "model = sklearn.linear_model.LogisticRegression(max_iter=10000, random_state=42)\n",
    "\n",
    "model.fit(train_inputs.numpy(), train_targets.numpy().flatten())\n",
    "\n",
    "train_accuracy = sklearn.metrics.accuracy_score(train_targets, model.predict(train_inputs))\n",
    "test_accuracy = sklearn.metrics.accuracy_score(test_targets, model.predict(test_inputs))\n",
    "print(f\"{train_accuracy=:.4f}, {test_accuracy=:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.25131344, 4.83503164, 4.15379776]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs: tensor([[0.6103],\n",
      "        [0.5886],\n",
      "        [0.5526],\n",
      "        ...,\n",
      "        [0.6010],\n",
      "        [0.5759],\n",
      "        [0.6023]], grad_fn=<SigmoidBackward0>)\n",
      "Loss: 0.6806437969207764\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an instance of the neural network\n",
    "model = SimpleNN()\n",
    "\n",
    "# Define loss function (binary cross entropy) and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Example of generating some dummy data\n",
    "# 10 samples, 3 features per sample\n",
    "# Binary targets (0 or 1)\n",
    "\n",
    "# Example of a forward pass (without training)\n",
    "outputs = model(train_inputs)\n",
    "\n",
    "# Loss calculation (no backward pass or optimization here)\n",
    "loss = criterion(outputs, train_targets)\n",
    "\n",
    "# Print the outputs and loss\n",
    "print(\"Outputs:\", outputs)\n",
    "print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 2/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 3/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 4/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 5/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 6/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 7/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 8/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 9/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 10/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 11/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 12/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 13/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 14/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 15/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 16/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 17/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 18/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 19/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 20/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 21/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 22/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 23/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 24/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 25/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 26/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 27/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 28/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 29/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 30/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 31/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 32/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 33/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 34/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 35/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 36/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 37/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 38/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 39/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 40/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 41/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 42/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 43/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 44/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 45/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 46/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 47/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 48/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 49/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 50/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 51/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 52/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 53/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 54/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 55/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 56/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 57/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 58/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 59/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 60/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 61/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 62/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 63/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 64/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 65/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 66/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 67/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 68/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 69/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 70/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 71/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 72/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9652\n",
      "Epoch 73/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 74/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 75/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 76/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 77/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 78/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 79/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 80/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 81/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 82/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 83/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 84/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 85/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 86/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 87/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 88/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 89/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 90/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 91/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 92/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 93/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 94/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 95/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 96/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 97/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 98/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 99/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n",
      "Epoch 100/100, Loss: 0.12, Train Accuracy: 0.9976, Validation Accuracy: 0.9673\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    model.train()\n",
    "    train_outputs = model(train_inputs)\n",
    "    loss = criterion(train_outputs, train_targets)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss every 20 epochs\n",
    "    \n",
    "    model.eval()\n",
    "    train_outputs = model(train_inputs)\n",
    "    val_outputs = model(test_inputs)\n",
    "    train_accuracy = torch.mean(((train_outputs > 0.5) == train_targets).float())\n",
    "    val_accuracy = torch.mean(((val_outputs > 0.5) == test_targets).float())\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.2f}, Train Accuracy: {train_accuracy.item():.4f}, Validation Accuracy: {val_accuracy.item():.4f}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight', tensor([[2.0077, 1.9070]])),\n",
       "             ('linear.bias', tensor([-1.9103]))])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 14)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idk = (np.array(feature_test_pred_proba[:, 1] > 0.5, dtype = np.float32) == y_valid.values)[np.invert(np.array(emoti_test_pred_proba[:, 1] > 0.5, dtype = np.float32) == y_valid.values)]\n",
    "idk.sum(), idk.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idk_val = (np.array(feature_train_pred_proba[:, 1] > 0.5, dtype = np.float32) == y_train.values)[np.invert(np.array(emoti_train_pred_proba[:, 1] > 0.5, dtype = np.float32) == y_train.values)]\n",
    "idk_val.sum(), idk_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.invert(np.array(emoti_test_pred_proba[:, 1] > 0.5, dtype = np.float32) == y_valid.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier()\n",
    "\n",
    "model.fit(train_inputs.numpy(), train_targets.numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuracy=1.0000, test_accuracy=0.9673\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = sklearn.metrics.accuracy_score(train_targets, model.predict(train_inputs))\n",
    "test_accuracy = sklearn.metrics.accuracy_score(test_targets, model.predict(test_inputs))\n",
    "print(f\"{train_accuracy=:.4f}, {test_accuracy=:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
