{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w7/stjx30757n5_hk7yzrbd5b8w0000gn/T/ipykernel_42347/958206930.py:23: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:281.)\n",
      "  train_feat_X = torch.tensor(train_feat, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 0.7008\n",
      "Epoch [10/20], Loss: 0.7005\n",
      "Epoch [15/20], Loss: 0.7002\n",
      "Epoch [20/20], Loss: 0.6999\n",
      "Validation Accuracy: 51.53%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read feature dataset\n",
    "train_feat = np.load(\"/Users/siya/Desktop/datasets/train/train_feature.npz\", allow_pickle=True)\n",
    "val_feat = np.load(\"/Users/siya/Desktop/datasets/valid/valid_feature.npz\", allow_pickle=True)\n",
    "train_feat_X = train_feat['features']\n",
    "train_feat_Y = train_feat['label']\n",
    "valid_feat_X = val_feat['features']\n",
    "valid_feat_Y = val_feat['label']\n",
    "\n",
    "# Flatten train and validation features using list comprehensions\n",
    "train_feat = [i.flatten() for i in train_feat_X]\n",
    "valid_feat = [i.flatten() for i in valid_feat_X]\n",
    "\n",
    "# Convert to tensors\n",
    "train_feat_X = torch.tensor(train_feat, dtype=torch.float32)\n",
    "valid_feat_X = torch.tensor(valid_feat, dtype=torch.float32)\n",
    "train_feat_Y = torch.tensor(train_feat_Y, dtype=torch.float32).unsqueeze(1)\n",
    "valid_feat_Y = torch.tensor(valid_feat_Y, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Define the model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(9984, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return torch.sigmoid(logits)\n",
    "\n",
    "model = NeuralNetwork()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training function\n",
    "def train(model, X, Y, optimizer, criterion, epochs=20):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Validation function\n",
    "def validate(model, X, Y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X)\n",
    "        predicted = (outputs > 0.5).float()  # Convert probabilities to binary predictions\n",
    "        accuracy = (predicted == Y).float().mean()\n",
    "        print(f'Validation Accuracy: {accuracy.item() * 100:.2f}%')\n",
    "        return predicted\n",
    "\n",
    "# Train the model\n",
    "train(model, train_feat_X, train_feat_Y, optimizer, criterion, epochs=20)\n",
    "\n",
    "# Validate the model and get predictions\n",
    "predicted_vals = validate(model, valid_feat_X, valid_feat_Y)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(valid_feat_Y.numpy(), predicted_vals.numpy())\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read feature dataset\n",
    "train_feat = np.load(\"/Users/siya/Desktop/datasets/train/train_feature.npz\", allow_pickle=True)\n",
    "val_feat = np.load(\"/Users/siya/Desktop/datasets/valid/valid_feature.npz\", allow_pickle=True)\n",
    "train_feat_X = train_feat['features']\n",
    "train_feat_Y = train_feat['label']\n",
    "valid_feat_X = val_feat['features']\n",
    "valid_feat_Y = val_feat['label']\n",
    "test_feat_X = np.load(\"/Users/siya/Desktop/datasets/test/test_feature.npz\", allow_pickle=True)['features']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: \n",
      "train_feat_X: (7080, 13, 768) train_feat_Y: (7080,)\n",
      "\n",
      "Test dataset size: \n",
      "test_feat_X: (2232, 13, 768)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train dataset size: \")\n",
    "print(f\"train_feat_X: {train_feat_X.shape} train_feat_Y: {train_feat_Y.shape}\")\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"Test dataset size: \")\n",
    "print(f\"test_feat_X: {test_feat_X.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 201377\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (7080x12256 and 12544x16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(train_feat_Y)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Ensure labels have shape (N, 1)\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n",
      "File \u001b[0;32m~/CS771 mini project /myproject_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CS771 mini project /myproject_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 31\u001b[0m, in \u001b[0;36mSimpleCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(x)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Apply the first fully connected layer\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# # Apply the output layer with sigmoid\u001b[39;00m\n",
      "File \u001b[0;32m~/CS771 mini project /myproject_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CS771 mini project /myproject_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/CS771 mini project /myproject_env/lib/python3.10/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (7080x12256 and 12544x16)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Convolutional layer: input channels=1, output channels=16, kernel size=3\n",
    "        self.conv1 = nn.Conv1d(in_channels=13, out_channels=16, kernel_size=3)\n",
    "        # ReLU activation\n",
    "        self.relu = nn.ReLU()\n",
    "        # Flatten the output of the convolution\n",
    "        self.flatten = nn.Flatten()\n",
    "        # Fully connected layer: reducing the size to 32\n",
    "        self.fc1 = nn.Linear(16 * 784, 16)  # Adjust 784 based on the output size of the conv layer\n",
    "        # Output layer: binary classification\n",
    "        self.fc2 = nn.Linear(16, 1)\n",
    "        # Sigmoid for binary classification\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolution and ReLU\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        # Flatten the output\n",
    "        x = self.flatten(x)\n",
    "        # Apply the first fully connected layer\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        # # Apply the output layer with sigmoid\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Print the number of trainable parameters\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {trainable_params}\")\n",
    "\n",
    "# Ensure the number of parameters is below 10,000\n",
    "# assert trainable_params <= 10000, \"Model has more than 10,000 trainable parameters!\"\n",
    "\n",
    "# Example training loop (without actual training data)\n",
    "# Replace train_feat_X, train_feat_Y, valid_feat_X, valid_feat_Y with your actual data\n",
    "# Assuming train_feat_X and valid_feat_X have shape (N, 13, 786)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training (dummy loop - adjust for actual data)\n",
    "for epoch in range(5):  # Run for 5 epochs (adjust as needed)\n",
    "    model.train()\n",
    "    # Example dummy batch data (replace with your actual training data)\n",
    "    inputs = torch.tensor(train_feat_X).float()  # Convert your NumPy array to a tensor\n",
    "    labels = torch.tensor(train_feat_Y).float().view(-1, 1)  # Ensure labels have shape (N, 1)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/5], Loss: {loss.item()}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    valid_inputs = torch.tensor(valid_feat_X).float()\n",
    "    valid_labels = torch.tensor(valid_feat_Y).float()\n",
    "    outputs = model(valid_inputs)\n",
    "    predictions = (outputs >= 0.5).int().view(-1).numpy()\n",
    "    valid_labels = valid_labels.int().numpy()\n",
    "\n",
    "    # Compute and display the confusion matrix\n",
    "    cm = confusion_matrix(valid_labels, predictions)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 13185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siya/miniconda3/envs/work_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Convolutional layer: input channels=1, output channels=16, kernel size=3\n",
    "        self.conv1 = nn.Conv1d(in_channels=13, out_channels=16, kernel_size=3)\n",
    "        # ReLU activation\n",
    "        self.relu = nn.ReLU()\n",
    "        # Flatten the output of the convolution\n",
    "        self.flatten = nn.Flatten()\n",
    "        # Fully connected layer: reducing the size to 32\n",
    "        self.fc1 = nn.Linear(16 * 784, 16)  # Adjust 784 based on the output size of the conv layer\n",
    "        # Output layer: binary classification\n",
    "        self.fc2 = nn.Linear(16, 1)\n",
    "        # Sigmoid for binary classification\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolution and ReLU\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        # Flatten the output\n",
    "        x = self.flatten(x)\n",
    "        # Apply the first fully connected layer\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        # # Apply the output layer with sigmoid\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Print the number of trainable parameters\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {trainable_params}\")\n",
    "\n",
    "# Ensure the number of parameters is below 10,000\n",
    "# assert trainable_params <= 10000, \"Model has more than 10,000 trainable parameters!\"\n",
    "\n",
    "# Example training loop (without actual training data)\n",
    "# Replace train_feat_X, train_feat_Y, valid_feat_X, valid_feat_Y with your actual data\n",
    "# Assuming train_feat_X and valid_feat_X have shape (N, 13, 786)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training (dummy loop - adjust for actual data)\n",
    "for epoch in range(5):  # Run for 5 epochs (adjust as needed)\n",
    "    model.train()\n",
    "    # Example dummy batch data (replace with your actual training data)\n",
    "    inputs = torch.tensor(train_feat_X).float()  # Convert your NumPy array to a tensor\n",
    "    labels = torch.tensor(train_feat_Y).float().view(-1, 1)  # Ensure labels have shape (N, 1)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/5], Loss: {loss.item()}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    valid_inputs = torch.tensor(valid_feat_X).float()\n",
    "    valid_labels = torch.tensor(valid_feat_Y).float()\n",
    "    outputs = model(valid_inputs)\n",
    "    predictions = (outputs >= 0.5).int().view(-1).numpy()\n",
    "    valid_labels = valid_labels.int().numpy()\n",
    "\n",
    "    # Compute and display the confusion matrix\n",
    "    cm = confusion_matrix(valid_labels, predictions)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten train and validation features using list comprehensions\n",
    "train_feat = [i.flatten() for i in train_feat_X]\n",
    "valid_feat = [i.flatten() for i in valid_feat_X]\n",
    "\n",
    "# Convert labels to float tensors in one step\n",
    "train_feat_Y = torch.tensor(train_feat_Y, dtype=torch.float32).unsqueeze(1)\n",
    "valid_feat_Y = torch.tensor(valid_feat_Y, dtype=torch.float32).unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(9984, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return torch.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siya/miniconda3/envs/work_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "def train(model, optimiser, mode):\n",
    "    if mode == 'train':\n",
    "        model.train()\n",
    "\n",
    "        loss = 0\n",
    "        for idx, train_data in enumerate(train_feat):\n",
    "            train_data = torch.tensor(train_data)\n",
    "            optimiser.zero_grad()\n",
    "            data = model(x=train_data)\n",
    "            print(data)\n",
    "            print(train_feat_Y[idx])\n",
    "            batch_loss = criterion(data, train_feat_Y[idx])\n",
    "            loss += batch_loss.item()\n",
    "\n",
    "            batch_loss.backward() #should be batch_loss not overall loss- inplace error, interferes with backpropagation\n",
    "            optimiser.step()\n",
    "        return data\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "        val_loss = 0\n",
    "        for idx, val_data in enumerate(valid_feat_X):\n",
    "            val_data = torch.tensor(val_data)\n",
    "            optimiser.zero_grad()\n",
    "            # val_data.to(device)\n",
    "            data = model(x=val_data)\n",
    "            batch_val_loss = criterion(data, valid_feat_Y[idx])\n",
    "            val_loss += batch_val_loss.item()\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_pred = []\n",
    "val_pred = []\n",
    "\n",
    "for epoch in range(50):\n",
    "    train_pred.append(train(model, optimiser, 'train'))\n",
    "    val_pred.append(train(model, optimiser, 'valid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = (train_pred >= 0.5).astype(int)\n",
    "y_pred_val = (val_pred >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred_train)\n",
    "\n",
    "# Create a confusion matrix display\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "\n",
    "# Plot the confusion matrix\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix: training dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred_val)\n",
    "\n",
    "# Create a confusion matrix display\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "\n",
    "# Plot the confusion matrix\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix: validation dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Common code for Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes, cmap=plt.cm.Blues, title='Confusion matrix'):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "    disp.plot(cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def get_classification_report(y_true, y_pred):\n",
    "    return classification_report(y_true, y_pred, target_names=['Class 0', 'Class 1'])\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred, title) :\n",
    "    \n",
    "    report = get_classification_report(y_true, y_pred)\n",
    "    print(report)\n",
    "    \n",
    "    plot_confusion_matrix(y_true, y_pred, classes = ['Class 0', 'Class 1'], title=title)\n",
    "    \n",
    "    print(f'Accuracy is {accuracy_score(y_true,y_pred)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
